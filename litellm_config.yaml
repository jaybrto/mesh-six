# LiteLLM Proxy configuration for mesh-six
# Reference config for all model routes used by agents.
# Deploy to the litellm namespace in k3s.

general_settings:
  master_key: "sk-local"

model_list:
  # Primary agent model (most agents default to this)
  - model_name: "anthropic/claude-sonnet-4-20250514"
    litellm_params:
      model: "anthropic/claude-sonnet-4-20250514"
      api_key: "os.environ/ANTHROPIC_API_KEY"

  # Researcher agent â€” Gemini for medium-complexity tasks
  - model_name: "gemini/gemini-2.0-flash"
    litellm_params:
      model: "gemini/gemini-2.0-flash"
      api_key: "os.environ/GOOGLE_API_KEY"

  # Local Ollama models (no API key needed)
  - model_name: "ollama/phi4-mini"
    litellm_params:
      model: "ollama/phi4-mini"
      api_base: "http://ollama.ollama:11434"

  # Context compression model
  - model_name: "ollama-phi3.5"
    litellm_params:
      model: "ollama/phi3.5"
      api_base: "http://ollama.ollama:11434"

litellm_settings:
  drop_params: true
  set_verbose: false
  request_timeout: 120
